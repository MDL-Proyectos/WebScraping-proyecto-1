
# Proyecto de Web Scraping: Estados Miembros de la ONU

Este repositorio contiene la primera etapa del proyecto. En esta fase se realiza un proceso de **Web Scraping** sobre la pÃ¡gina de Wikipedia que lista los [Estados miembros de las Naciones Unidas](https://es.wikipedia.org/wiki/Estado_miembro_de_las_Naciones_Unidas).

## ğŸŒ Objetivo
Extraer informaciÃ³n estructurada sobre los paÃ­ses miembros de la ONU desde Wikipedia, para su posterior almacenamiento y anÃ¡lisis en etapas futuras del proyecto (PostgreSQL y ETL).

## ğŸ› ï¸ TecnologÃ­as utilizadas
- Python 3
- Requests
- BeautifulSoup4
- time (para respetar la infraestructura del sitio)

## ğŸ“¦ InstalaciÃ³n
Es necesario de tener Python 3 instalado. TambiÃ©n instalar las siguientes dependencias necesarias:

```bash
pip install requests beautifulsoup4
```

## â–¶ï¸ EjecuciÃ³n
EjecutÃ¡ el script principal para iniciar el scraping:

```bash
python book-scraping.py
```

El script extrae los nombres de los paÃ­ses miembros de la ONU y los guarda en un archivo CSV o JSON para su posterior uso.

## âš–ï¸ Consideraciones Ã©ticas
Este proyecto respeta las buenas prÃ¡cticas de scraping:
- Se utiliza `time.sleep()` para evitar sobrecargar los servidores de Wikipedia.
- Se accede Ãºnicamente a contenido pÃºblico.
- Se reconoce que Wikipedia ofrece una API oficial como alternativa mÃ¡s eficiente.

## ğŸ“ Estructura del repositorio
```
â”œâ”€â”€ book-scraping.py         # Script principal de scraping
â”œâ”€â”€ paises.csv    # Archivo generado con los datos extraÃ­dos en CSV
â”œâ”€â”€ paises.json    # Archivo generado con los datos extraÃ­dos en JSON
â”œâ”€â”€ README.md               # DocumentaciÃ³n del proyecto
```

## âœï¸ Autor
Matias DL
